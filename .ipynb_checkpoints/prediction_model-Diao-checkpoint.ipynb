{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict(filename, key, value):\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        \n",
    "        #create map\n",
    "        dict_ = dict()\n",
    "        \n",
    "        for row in reader:\n",
    "            key_val = row[key]\n",
    "            val_val = row[value]\n",
    "            dict_[int(key_val)] = int(val_val)\n",
    "        \n",
    "        return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "project_map = get_dict('data/encoding/project_id_encoding.csv', 'project_id', 'mapping_number')\n",
    "user_map = get_dict('data/encoding/user_id_encoding.csv', 'user_id', 'number_map')\n",
    "print(len(user_map))\n",
    "print(len(project_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        \n",
    "        #create required collections\n",
    "        project_id = list()\n",
    "        user_id = list()\n",
    "        members = list()\n",
    "        mentions = list()\n",
    "        message_number = list()\n",
    "        \n",
    "        for row in reader:\n",
    "            project_id.append(row['project_id'].rstrip().split(' '))\n",
    "            user_id.append(row['user_id'].rstrip().split(' '))\n",
    "            members.append(row['members'].rstrip().split(' '))\n",
    "            mentions.append(row['mentions'].rstrip().split(' '))\n",
    "            message_number.append(row['message_number'].rstrip().split(' '))\n",
    "        if '' in members:\n",
    "            print('True')\n",
    "            members.remove('')\n",
    "        if ' ' in mentions:\n",
    "            print('True')\n",
    "            mentions.remove('')\n",
    "        return project_id, user_id, members, mentions, message_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_list(filename):\n",
    "    project_id, user_id, members, mentions, message_number = read_data(filename)\n",
    "    return project_id, user_id, members, mentions, message_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(data_list, dict_):\n",
    "    one_hot_list = np.zeros((len(data_list), len(dict_)))\n",
    "    index = 0\n",
    "    for sub_list in data_list:\n",
    "        one_hot_encode = np.zeros((len(dict_),))\n",
    "        row_number = 1\n",
    "        for single_data in sub_list:\n",
    "            if single_data == '0':\n",
    "                continue\n",
    "            if single_data != '':\n",
    "                one_hot_encode[dict_[int(single_data)] - 1] = 1\n",
    "        row_number += 1\n",
    "        one_hot_list[index, :] = one_hot_encode\n",
    "        index += 1\n",
    "    return one_hot_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_message(message_list):\n",
    "    sum_list = np.array((message_list))\n",
    "    index = 0\n",
    "    for sub_list in message_list:\n",
    "        if '' in sub_list:\n",
    "            sub_list.remove('')\n",
    "        sub_list = list(map(int, sub_list))\n",
    "        sum_list[index] = sum(sub_list)\n",
    "        index += 1\n",
    "    return sum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label(project_id, project_map):\n",
    "    return transform_data(project_id, project_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_id_data(user_id, user_map):\n",
    "    return transform_data(user_id, user_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_member_data(members, user_map):\n",
    "    for sub_list in members:\n",
    "        if '1' in sub_list:\n",
    "            sub_list.remove('1')\n",
    "        elif '160' in sub_list:\n",
    "            sub_list.remove('160')\n",
    "        elif '' in sub_list:\n",
    "            sub_list.remove('')\n",
    "    members_data = transform_data(members, user_map)\n",
    "    return members_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mention_data(mentions, user_map):\n",
    "    for sub_list in mentions:\n",
    "        if '1' in sub_list:\n",
    "            sub_list.remove('1')\n",
    "        elif '160' in sub_list:\n",
    "            sub_list.remove('160')\n",
    "    mentions_data = transform_data(mentions, user_map)\n",
    "    return mentions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_data(filename):\n",
    "    project_id, user_id, members, mentions, message_number = get_data_list(filename)\n",
    "    label_data = get_label(project_id, project_map)\n",
    "    user_id_data = get_user_id_data(user_id, user_map)\n",
    "    member_data = get_member_data(members, user_map)\n",
    "    mentions_data = get_mention_data(mentions, user_map)    \n",
    "    message_number = count_message(message_number)\n",
    "    print('Size of user_id: ', user_id_data.shape)\n",
    "    print('Size of member_data: ', member_data.shape)\n",
    "    print('Size of mentions_data: ', mentions_data.shape)\n",
    "    print('Size of message_number: ', message_number.shape)\n",
    "    train_data = np.zeros((user_id_data.shape[0], user_id_data.shape[1] + member_data.shape[1] + mentions_data.shape[1] +  1))\n",
    "    train_data[:, 0:user_id_data.shape[1]] = user_id_data\n",
    "    train_data[:, user_id_data.shape[1]:user_id_data.shape[1] + member_data.shape[1]] = member_data\n",
    "    train_data[:, user_id_data.shape[1] + member_data.shape[1] : train_data.shape[1] - 1] = mentions_data\n",
    "    train_data[:, train_data.shape[1] - 1] = message_number\n",
    "    return train_data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_train_test_data(train_data, label_data):\n",
    "    data = np.zeros((train_data.shape[0], train_data.shape[1] + label_data.shape[1]))\n",
    "    data[:, 0:label_data.shape[1]] = label_data\n",
    "    data[:,label_data.shape[1]:] = train_data\n",
    "    np.random.shuffle(data)\n",
    "    n_test = math.floor(0.1 * data.shape[0])\n",
    "    print('Number of test: ', n_test)\n",
    "    test = data[0:n_test,:]\n",
    "    train = data[n_test:,:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of user_id:  (5027, 58)\n",
      "Size of member_data:  (5027, 58)\n",
      "Size of mentions_data:  (5027, 58)\n",
      "Size of message_number:  (5027,)\n",
      "(5027, 175)\n",
      "(5027, 83)\n",
      "Number of test:  502\n"
     ]
    }
   ],
   "source": [
    "train_data, label_data = form_data('data/Final_file.csv', )\n",
    "print(train_data.shape)\n",
    "print(label_data.shape)\n",
    "train, test = form_train_test_data(train_data, label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Relevance, Classifier Chain and Label Powerset are used to transform the multi_label problem to a single label problem.\n",
    "\n",
    "\n",
    "|                           | Binary Relevance | Classifier Chain | Label Powerset |\n",
    "|---------------------------|----------------- | ---------------- | -------------- |\n",
    "|  Guassian Naive Bayesian  |  0.0319          |      0.0319      |   0.1335       |\n",
    "|  Multiple Neural Network  |  0.253           |       0.255      |   0.1375       |\n",
    "|  Random Forest            |   0.263          |      0.247       |   0.269        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train[:, 0:label_data.shape[1]]\n",
    "X_train = train[:,label_data.shape[1]:]\n",
    "\n",
    "Y_test = test[:, 0:label_data.shape[1]]\n",
    "X_test = test[:,label_data.shape[1]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayesian classification + Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03187250996015936"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Neural Network + Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25298804780876494"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', activation='relu',alpha=1e-4,hidden_layer_sizes=(50,50), random_state=1,max_iter=1000,verbose=10,learning_rate_init=.1)\n",
    "\n",
    "classifier = BinaryRelevance(mlp)\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayesian + Classifier Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03187250996015936"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = ClassifierChain(GaussianNB())\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network + Classifier Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2549800796812749"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', activation='relu',alpha=1e-4,hidden_layer_sizes=(50,50), random_state=1,max_iter=1000,verbose=10,learning_rate_init=.1)\n",
    "\n",
    "classifier = ClassifierChain(mlp)\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayesian + Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13346613545816732"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LabelPowerset(GaussianNB())\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network + Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13745019920318724"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', activation='relu',alpha=1e-4,hidden_layer_sizes=(50,50), random_state=1,max_iter=1000,verbose=10,learning_rate_init=.1)\n",
    "\n",
    "classifier = LabelPowerset(mlp)\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
